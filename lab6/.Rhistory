legend("topright", names_cols_airplan_crushes[10:12], col=rainbow(3), lwd=5, bty = "n",  y.intersp = 0.8, text.width = 6)
# Считывание олимпийцев
olympics <- read.csv(file = "C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab7/athlete_events.csv",
sep = ",", header = TRUE, dec = ',')
# Спортсмены по гимнастике
gymnastics_athlets <- subset(olympics, Sport == 'Gymnastics')
# Удалим строки, где есть пустые значения в весе
gymnastics_athlets[gymnastics_athlets == ""] <- NA # Пустые значение, сделали NA
gymnastics_athlets <- gymnastics_athlets[rowSums(is.na(gymnastics_athlets[,1:6])) == 0,]
# Убрали повторяющиеся строки со спортсменами
gymnastics_athlets <- gymnastics_athlets %>% group_by(ID) %>% filter (! duplicated(ID))
library(dplyr)
# Убрали повторяющиеся строки со спортсменами
gymnastics_athlets <- gymnastics_athlets %>% group_by(ID) %>% filter (! duplicated(ID))
# Выбрали мужчин
gymnastics_athlets_man <- gymnastics_athlets[gymnastics_athlets$Sex == 'M',]
# Вес спортсменов
weight <- as.numeric(gymnastics_athlets_man$Weight)
# Гистограмма веса
hist(weight, main='Вес спорсменов',
xlab='Вес', ylab='Частота',xlim = c(40,90))
# Проверка выборки на нормальность распределения с помощью Квантильно-квантильного графика
# (показывает распределение данных относительно ожидаемого нормального распределения)
qqnorm(weight)
qqline(weight, col='blue', lwd = 5)
# Доверительные интервалы
library(car)
qqPlot(weight)
# Тест Стьюдента
t.test(weight, mu=65)
# Тест Стьюдента
t.test(weight, mu=63.2)
# Гистограмма веса
hist(weight, main='Вес спорсменов',
xlab='Вес', ylab='Частота',xlim = c(40,90))
# Тест Шапиро-Уилкса для проверки на нормальность
shapiro.test(weight[1:4999])
# Тест Уилкоксона
wilcox.test(weight, mu=65, conf.int = TRUE)
# Тест Стьюдента
t.test(weight, mu=63)
# Выборка гимнастов и атлетов
gymnastics_athletics_men <- subset(olympics, Sex == 'M' & (Sport == 'Gymnastics' | Sport == 'Athletics'))
# Удалим строки, где есть пустые значения в весе
gymnastics_athletics_men[gymnastics_athletics_men == ""] <- NA # Пустые значение, сделали NA
gymnastics_athletics_men <- gymnastics_athletics_men[rowSums(is.na(gymnastics_athletics_men[,1:6])) == 0,]
# Убрали повторяющиеся строки со спортсменами
gymnastics_athletics_men <- gymnastics_athletics_men %>% group_by(ID) %>% filter (! duplicated(ID))
weight_gymnastics_athletics_men <- as.numeric(gymnastics_athletics_men$Weight)
# Гистограмма веса
hist(weight_gymnastics_athletics_men, main='Гистограмма веса гимнастов и атлетов', xlab='Вес', xlim = c(40,150), ylim = c(0,5000))
# Гистограмма веса
hist(weight_gymnastics_athletics_men, main='Гистограмма веса гимнастов и атлетов', xlab='Вес', xlim = c(40,150), ylim = c(0,5000))
library("xlsx")
library(stringr)
airplan_crushes <- read.csv('C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab6/Airplane_Crashes.csv', sep = ",") # Считали базу данных
names_cols_airplan_crushes <- c("Дата", "Время", "Место крушения", "Компания",
"Полет", "Рейс", "Самолет", "Бортовой номер",
"Заводской серийный номер", "Находилось на борту",
"Cмертельные случаи на борту", "Убитые при приземлении",
"Описание крушения") # Название столбцов
colnames(airplan_crushes) <- names_cols_airplan_crushes # Присвоили имена столбикам
airplan_crushes[airplan_crushes == ""] <- NA # Пустые значение, сделали NA
# Удалим строки, где есть пустые значения
airplan_crushes <- airplan_crushes[rowSums(is.na(airplan_crushes[,])) == 0,]
airplan_crushes <- airplan_crushes[800:944,]
# Время
time <- gsub(":","",airplan_crushes[,2])
time <- as.numeric(gsub("(^|[^0-9])0+", "\\1", time, perl = TRUE))
airplan_crushes[,2] <- time
airplan_crushes[airplan_crushes == ""] <- NA # Пустые значение, сделали NA
# Удалим строки, где есть пустые значения
airplan_crushes <- airplan_crushes[rowSums(is.na(airplan_crushes[,])) == 0,]
# Нормализация переменных
airplane_N <- airplan_crushes[,c(2,10,11,12)]
maxs <- apply(airplane_N, 2, max) # Максимальное значение
mins <- apply(airplane_N, 2, min) # Минимальное значение
airplane_N[airplane_N == ""] <- NA # Пустые значение, сделали NA
# Удалим строки, где есть пустые значения
airplane_N <- airplane_N[rowSums(is.na(airplane_N[,])) == 0,]
airplane_N <- scale(airplane_N, center = mins, scale = maxs - mins)
# Матрица попарных расстояний
dist.airplan_crushes <- dist(airplane_N)
# Проводим кластерный анализ, результаты записываем в список clust.airplan_crushes
clust.airplan_crushes <- hclust(dist.airplan_crushes, "ward.D")
labels <- airplan_crushes[,7]
# Дендрограмма
plot(clust.airplan_crushes, labels, cex=0.5, main="Дендрограмма кластеров",
xlab="Самолеты")
# целесообразно разделить ее на 3 кластера.
rect.hclust(clust.airplan_crushes, k=3, border="red")
# Разбиение дендрограммы на кластеры
groups <- cutree(clust.airplan_crushes, k = 3)
airplan_crushes[groups==1, 7]
airplan_crushes[groups==2, 7]
airplan_crushes[groups==3, 7]
View(airplan_crushes)
labels <- airplan_crushes[,7]
# Дендрограмма
plot(clust.airplan_crushes, labels, cex=0.5, main="Дендрограмма кластеров",
xlab="Самолеты")
# целесообразно разделить ее на 3 кластера.
rect.hclust(clust.airplan_crushes, k=3, border="red")
# Разбиение дендрограммы на кластеры
groups <- cutree(clust.airplan_crushes, k = 3)
airplan_crushes[groups==1, 7]
airplan_crushes[groups==2, 7]
airplan_crushes[groups==3, 7]
#par(mar = c(4, 5, 6, 4))
# Вычисляем среднее значение показателей в каждом кластере
#  в 1-ом кластере
g1<-colMeans(airplan_crushes[groups==1,c(2,10,11,12)])
#  во 2-ом кластере
g2<-colMeans(airplan_crushes[groups==2,c(2,10,11,12)])
#  в 3-ем кластере
g3<-colMeans(airplan_crushes[groups==3,c(2,10,11,12)])
# Построение столбчатой диаграммы
df <- data.frame(g1,g2,g3)
rownames(df) <- c("Время", "Количество на борту", "Умерло на борту", "Умерло не на борту")
barplot(data.matrix(df), main="Группы самолетов", col=rainbow(4), ylim = c(0,2400), beside = TRUE)
legend("topright", c("Время", "Количество на борту", "Умерло на борту", "Умерло не на борту"),
col=rainbow(4), lwd=5, bty = "n",  y.intersp = 0.8, text.width = 6)
labels <- airplan_crushes[,7]
# Дендрограмма
plot(clust.airplan_crushes, labels, cex=0.5, main="Дендрограмма кластеров",
xlab="Самолеты")
# целесообразно разделить ее на 3 кластера.
rect.hclust(clust.airplan_crushes, k=3, border="red")
# Разбиение дендрограммы на кластеры
groups <- cutree(clust.airplan_crushes, k = 3)
# Каменная осыпь
plot(1:143, clust.airplan_crushes$height, type='b', main = "Диаграмма каменная осыпь")
library(lattice)
# Двумерные диаграммы рассеяния
xyplot(airplan_crushes[,10] ~ airplan_crushes[,11], airplan_crushes, main='Зависимость количества людей на борту от летальных случаев на борту',
xlab='Смертельные случаи на борту', ylab='Находились на борту',  auto.key = TRUE, groups = groups)
# Построим боксплот
boxplot(airplan_crushes[,2] ~ groups, data = iris, ylab = "Время крушения", frame = FALSE, col = "lightgray")
#-------------------------------------------------------------
# Классификация по формуле Байеса
library(klaR)
# Вычисление вероятностей по всем признакам
naive_airplan_crushes <- NaiveBayes(airplane_N$groups_f ~ ., data = airplane_N)
library("xlsx")
airplan_crushes <- read.csv('C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab6/Airplane_Crashes.csv', sep = ",") # Считали базу данных
names_cols_airplan_crushes <- c("Дата", "Время", "Место крушения", "Компания",
"Полет", "Рейс", "Самолет", "Бортовой номер",
"Заводской серийный номер", "Находилось на борту",
"Cмертельные случаи на борту", "Убитые при приземлении",
"Описание крушения") # Название столбцов
colnames(airplan_crushes) <- names_cols_airplan_crushes # Присвоили имена столбикам
airplan_crushes[airplan_crushes == ""] <- NA # Пустые значение, сделали NA
# Удалим строки, где есть пустые значения
airplan_crushes <- airplan_crushes[rowSums(is.na(airplan_crushes[,])) == 0,]
airplan_crushes <- airplan_crushes[800:944,]
# Время
time <- gsub(":","",airplan_crushes[,2])
time <- as.numeric(gsub("(^|[^0-9])0+", "\\1", time, perl = TRUE))
airplan_crushes[,2] <- time
# Нормализация переменных
airplane_N <- airplan_crushes[,c(2,10,11,12)]
airplane_N[airplane_N == ""] <- NA # Пустые значение, сделали NA
# Удалим строки, где есть пустые значения
airplane_N <- airplane_N[rowSums(is.na(airplane_N[,])) == 0,]
airplan_crushes[airplan_crushes == ""] <- NA # Пустые значение, сделали NA
# Удалим строки, где есть пустые значения
airplan_crushes <- airplan_crushes[rowSums(is.na(airplan_crushes[,])) == 0,]
maxs <- apply(airplane_N, 2, max) # Максимальное значение
mins <- apply(airplane_N, 2, min) # Минимальное значение
airplane_N <- scale(airplane_N, center = mins, scale = maxs - mins)
# Матрица попарных расстояний
dist.airplan_crushes <- dist(airplane_N)
# Проводим кластерный анализ, результаты записываем в список clust.airplan_crushes
clust.airplan_crushes <- hclust(dist.airplan_crushes, "ward.D")
labels <- airplan_crushes[,7]
# Дендрограмма
plot(clust.airplan_crushes, labels, cex=0.5, main="Дендрограмма кластеров",
xlab="Самолеты")
# целесообразно разделить ее на 3 кластера.
rect.hclust(clust.airplan_crushes, k=3, border="red")
# Разбиение дендрограммы на кластеры
groups <- cutree(clust.airplan_crushes, k = 3)
# Преобразование в фактор
groups_f <- factor(groups)
airplane_N <- data.frame(airplane_N)
airplane_N <- cbind(airplane_N, groups_f)
#-------------------------------------------------------------
# Классификация по формуле Байеса
library(klaR)
# Вычисление вероятностей по всем признакам
naive_airplan_crushes <- NaiveBayes(airplane_N$groups_f ~ ., data = airplane_N)
naive_airplan_crushes$tables
# Ядерные функции плотности условной вероятности
layout(matrix(c(1,2,3,4), 2, 2, byrow = TRUE))
plot(naive_airplan_crushes,legendplot=FALSE)
legend("top", legend=c("g1", "g2", "g3"),lty=1:3, cex=1)
legend("top", legend=c("g1", "g2", "g3"),color = rainbow(3), lty=1:3, cex=1)
legend("top", legend=c("g1", "g2", "g3"),color = c("red","green","blue"), lty=1:3, cex=1)
legend("top", legend=c("g1", "g2", "g3"),colors = c("red","green","blue"), lty=1:3, cex=1)
legend("top", legend=c("g1", "g2", "g3"),col = c("red","green","blue"), lty=1:3, cex=1)
# Классификация по вероятностным данным
predict <- predict(naive_airplan_crushes, airplane_N[,-6])$class
# Соотношение фактического расстояния и прогноза
table(Группа = airplane_N$groups_f, Прогноз = predict)
# Вычисление точности классификации по формуле Байеса
accuracy_bayes <- mean(predict == airplane_N$groups_f)
accuracy_bayes
# Соотношение фактического расстояния и прогноза
table(Группа = airplane_N$groups_f, Прогноз = predict)
# Вычисление точности классификации по формуле Байеса
accuracy_bayes <- mean(predict == airplane_N$groups_f)
paste("Точность=", round(100*accuracy_bayes, 2), "%", sep = "")
# Классификация с помощью дерева решений Decision Tree
set.seed(1234)
# Индексирование данных, для 1 вероятность 60%, для 2 - 40%
index <- sample(2, nrow(airplane_N), replace=TRUE, prob=c(0.7, 0.3))
# Разделение на обучающую и тестовую выборки
trainData <- airplane_N[index==1,]
testData <- airplane_N[index==2,]
nrow(trainData)
nrow(testData)
nrow(airplane_N)
library(party)
# Построение модели
# Указываем зависимость групп от каждого параметра
formula <- groups_f ~ Находилось.на.борту+Cмертельные.случаи.на.борту+Убитые.при.приземлении+Время
airplane_ctree <- ctree(formula, trainData)
# Обучение модели
predict(airplane_ctree)
trainData$groups_f
table(predict(airplane_ctree), trainData$groups_f)
plot(airplane_ctree)
# Применение модели
test_predict <- predict(airplane_ctree, newdata=testData)
table(test_predict, testData$groups_f)
accuracy_tree <- mean(test_predict == testData$groups_f)
accuracy_tree
# Алгоритм Random Forest
library(randomForest)
# Обучение модели
forest <- randomForest(groups_f ~ .,trainData, ntree=20, proximity=TRUE)
table(predict(forest), trainData$groups_f)
# Применение на тестовой выборке
test_forest <- randomForest(groups_f ~ .,testData, ntree=20, proximity=TRUE)
table(predict(test_forest), testData$groups_f)
accuracy_forest <- mean(predict(test_forest) == testData$groups_f)
accuracy_forest
input_table <- read.csv(file = "C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab8/Lab8_Data.csv",
sep = ",", header = TRUE, dec = ',')
# Описание
definitions <- read.csv(file = "C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab8/Lab8_Definition and Source.csv",
sep = ",", header = TRUE, dec = ',')
# Данные по Индии
india <- subset(input_table, Country.Code == "IND")
# Индия
# Приведение датасета к необходимому формату
years <- c(1989:2017)
ind <- c("ВВП", "ВВП рост", "Рождаемость", "Динамика рож.", "Заемщики", "Безраб(выс)", 'Безработные(баз)', "Импорт", "Промышленность", "Расходы на мед.",
"Продол. жизни", "Прирост популяции", "Расходы на образ", "Объем импорта", "Экспорт",
"Смертностьь", "Образованных", "Образованных(ж)", "Экспорт High-tech", "Лучшая индустр", "Науч статей")
indicators <- india[,3]
india <- india[-c(8,9),-c(1,2,3,4,34)]
# Преобразование в числовой тип
india <- sapply(india, as.numeric)
# Транспонирование
india <- t(india)
rownames(india) <- years
colnames(india) <- ind
india <- data.frame(india)
# График распределения ВВП по годам
plot(years, india[,1], main="Прирост ВВП", xlab='Годы',
ylab='ВВП (в долларах)', type='o', pch=20)
# Корреляционная матрица (учитываются все полные наблюдения для каждой пары переменных в отдельности)
cor(india, use="pairwise.complete.obs")
# Визуализация корреляционной матрицы
library(corrplot)
# Ellipses
corrplot(cor(india, use="everything"),mar = c(0, 0, 0, 0), method = "ellipse",tl.cex = 0.6,add = FALSE)
input_table <- read.csv(file = "C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab8/Lab8_Data.csv",
sep = ",", header = TRUE, dec = ',')
# Описание
definitions <- read.csv(file = "C:/Users/kosty/OneDrive/Документы/GitHub/Big_Data_R/lab8/Lab8_Definition and Source.csv",
sep = ",", header = TRUE, dec = ',')
# Данные по Индии
india <- subset(input_table, Country.Code == "IND")
# Индия
# Приведение датасета к необходимому формату
years <- c(1989:2017)
ind <- c("ВВП", "ВВП рост", "Рождаемость", "Динамика рож.", "Заемщики", "Безраб(выс)", 'Безработные(баз)', "Импорт", "Промышленность", "Расходы на мед.",
"Продол. жизни", "Прирост популяции", "Расходы на образ", "Объем импорта", "Экспорт",
"Смертностьь", "Образованных", "Образованных(ж)", "Экспорт High-tech", "Лучшая индустр", "Науч статей")
indicators <- india[,3]
india <- india[-c(8,9),-c(1,2,3,4,34)]
# Преобразование в числовой тип
india <- sapply(india, as.numeric)
# Транспонирование
india <- t(india)
rownames(india) <- years
colnames(india) <- ind
india <- data.frame(india)
# График распределения ВВП по годам
plot(years, india[,1], main="Прирост ВВП", xlab='Годы',
ylab='ВВП (в долларах)', type='o', pch=20)
# Корреляционная матрица (учитываются все полные наблюдения для каждой пары переменных в отдельности)
cor(india, use="pairwise.complete.obs")
# Визуализация корреляционной матрицы
library(corrplot)
# Ellipses
corrplot(cor(india, use="everything"),mar = c(0, 0, 0, 0), method = "ellipse",tl.cex = 0.6,add = FALSE)
# Корреляция роста ВВП и прироста населения
cor(india$ВВП, india$Прирост.популяции)
plot(india$ВВП, india$Прирост.популяции, main='Зависимость популяции от ВВП',
xlab="Прирост ВВП", ylab="Популяция")
# Корреляция прироста населения на динамику безработицы
cor(india$Прирост.популяции, india$Безработные.баз., use='pairwise.complete.obs')
plot(india$Прирост.популяции, india$Безработные.баз.,
main="Корреляция прироста населения на динамику безработицы",
xlab="Популяция", ylab="Безработица")
# Корреляция расходов на медицину на увеличение продолжительности жизни
cor(india$Расходы.на.мед., india$Продол..жизни, use="pairwise.complete.obs")
plot(india$Расходы.на.мед., india$Продол..жизни,
main="Корреляция расходов на медицину на увеличение продолжительности жизни",
xlab='Расходы на медицину', ylab="Продолжительность жизни")
# Корреляция расходов на медицину на смертность
cor(india$Расходы.на.мед., india$Смертность, use="pairwise.complete.obs")
plot(india$Расходы.на.мед., india$Смертность,
main="Корреляция расходов на медицину на смертность",
xlab="Расходы на медицину", ylab="Смертность")
library(car)
scatterplotMatrix(india[,c(1,4,8,11,12)], spread=FALSE, lty.smooth=4)
# Полиномиальная регрессионная модель зависимости продолжительности жизни от ВВП
model <- lm(india$Продол..жизни ~ india$ВВП + I(india$ВВП^2), india)
model
summary(model)
plot(india$Продол..жизни ~ india$ВВП)
#График полиномиальной регрессии
lines(india$ВВП, fitted(model))
#===============================================================================
# Задание 1
# 1.	Создайте кольцевой граф  g со случайным числом вершин G_size  124
G_size <- sample(c(26:124),1)
g1<-graph.ring(n = G_size)
library("igraph")
library("network")
library("sna")
#===============================================================================
# Задание 1
# 1.	Создайте кольцевой граф  g со случайным числом вершин G_size  124
G_size <- sample(c(26:124),1)
g1<-graph.ring(n = G_size)
coords <- layout_(g1, as_star())
# Количество вершин
vcount(g1)
# Количество ребер
ecount(g1)
# Матрица смежности
g1[]
plot(g1, main='Кольцевой граф', edge.arrow.size=.9,vertex.size=15)
# 2.	Создайте  граф g1 из  пустого графа с числом вершин G_size  желтого цвета.
g1<-graph.empty()+vertices(1:G_size,color="yellow")
g1[]
plot(g1, main = "Пустой граф")
# Добавьте ему 8 случайных ребер, сформированных из вектора вершин, окрасьте ребра красным цветом,
g1 <- g1 + edges(sample(V(g1), 16, replace=TRUE), replace=TRUE, color="red")
# Добавьте ему 8 случайных ребер, сформированных из вектора вершин, окрасьте ребра красным цветом,
g1 <- g1 + edges(sample(V(g1), 128, replace=TRUE), replace=TRUE, color="red")
g1[]
plot(g1, main = "Добавили красных ребер", layout = coords, edge.arrow.size=.2)
# Добавьте графу g1 еще  16 случайных ребер, сформированных из вектора вершин, окрасьте ребра синим цветом
g1 <- g1 + edges(sample(V(g1), 160, replace=TRUE), replace=TRUE, color="blue")
g1[]
plot(g1, layout = coords, main="Добавили синих ребер", edge.arrow.size=.2)
edges <- c(55,52, 54,31, 31,24, 32,33, 23,29)
i <- 1
while(i <= length(edges)){
if((edges[i] %in% V(g1)) && (edges[i+1] %in% V(g1)))
g1 <- g1 + edges(c(edges[i],edges[i+1]), replace=TRUE, color="black")
#add.edges(g1, c(edges[i],edges[i+1]),  color="black")
i <- i+1
}
plot(g1, layout = coords, main="Добавили черных ребер", edge.arrow.size=.2)
# Выведите соседей N - й вершины
neighbors(g1, V(g1)[16], mode = 1)
incident(g1, V(g1)[16], mode=("all"))
are_adjacent(g1, 26, 28)
# 4. 4.	Добавьте еще одну вершину и подключите ее к той, которая имеет
# наибольшее количество связанных с ней узлов
# Степень для каждой вершины
deg<-igraph::degree(g1)
deg
# Первая максимальная
max_ver <- which(deg == max(deg))[[1]]
incident(g1,V(g1)[max_ver], mode=c("all", "out", "in", "total"))
# Добавляем новую вершину
g1 <- g1 + vertices("New", color="pink") + edges(c(max_ver,"New"), replace=TRUE, color="green")
plot(g1, layout=layout.circle, main="Добавили новую вершину", edge.arrow.size=.2)
# Алфавит
alf<-c(65:90,97:122,1040:1103)
alf<-intToUtf8(alf)
V(g1)$alf
plot(g1, main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[[1]][1:G_size])
# Алфавит
alf<-c(65:90,97:122,1040:1103)
alf<-intToUtf8(alf)
V(g1)$alf
plot(g1, main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[[1]][1:G_size])
g1[]
# Алгоритмы размещения
plot(g1, layout=layout_as_tree, edge.arrow.size=.4, main='Дерево')
plot(g1, main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[[1]][1:G_size])
alf <- strsplit(alf, " ")[[1]]
plot(g1, main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[[1]][1:G_size])
alf <- strsplit(alf, "")[[1]]
plot(g1, main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[[1]][1:G_size])
plot(g1, main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf)
plot(g1, layout=layout.circle,main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf)
alf[1:G_size]
plot(g1, layout=layout.circle,main="Переименнованный граф", vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[1:G_size])
plot(g1, layout=layout.circle,main="Переименнованный граф",edge.arrow.size=.2, vertex.color="white", vertex.size=8, vertex.frame.color="yellow", vertex.label=alf[1:G_size])
# Алгоритмы размещения
plot(g1, layout=layout_as_tree, edge.arrow.size=.4, main='Дерево')
plot(g1, layout=layout.kamada.kawai, edge.arrow.size=.4, main='Алгоритм Камада-Каваи')
plot(g1, layout=layout.kamada.kawai, vertex.size=2,edge.arrow.size=.4, main='Алгоритм Камада-Каваи')
plot(g1, layout=layout.fruchterman.reingold, vertex.size=2,edge.arrow.size=.4, main='Алгоритм Фрюхтермана-Рейнгольда')
# Измерение диаметра графа
diameter(g1)
all_simple_path_g1 <- list()
for (i in 1:length(V(g1))) {
all_simple_path_g1 <- append(all_simple_path_g1, all_shortest_paths(g1, i, to = V(g1), mode = c("out", "all", "in"), weights = NULL))
}
all_simple_path_g1
# Измерение диаметра графа
diameter(g1)
ver <- 1:8
# Создание графа
graph <- list("7" = c("1", "2"),
"1" = c("7", "2", "3", "4"),
"2" = c("7", "1", "3", "4"),
"3" = c("1", "2", "4", "5", "6"),
"4" = c("1", "2", "3", "5", "6"),
"5" = c("3", "4", "6", "8"),
"6" = c("3", "4", "5", "8"),
"8" = c("5", "6"))
# Веса
weights <- list("7" = c(3, 5),
"1" = c(3, 3, 10, 11),
"2" = c(5, 3, 2, 3),
"3" = c(10, 2, 3, 7, 12),
"4" = c(11, 3, 3, 11, 2),
"5" = c(7, 11, 3, 2),
"6" = c(12, 2, 3, 2),
"8" = c(2, 2))
G <- data.frame(stack(graph), weights = stack(weights)[[1]])
set.seed(500)
el <- as.matrix(stack(graph))
g <- graph_from_edgelist(el)
plot(g, edge.label = stack(weights)[[1]])
# Функция нахождения длины путя
path_length <- function(path) {
# Если путь равен НУЛЮ, вернем бесконечную длину
if (is.null(path)) return(Inf)
# получить все последовательные узлы
pairs <- cbind(values = path[-length(path)], ind = path[-1])
# объедините с помощью G и суммируем по весам
sum(merge(pairs, G)[ , "weights"])
}
# Алгоритм Деикстры
find_shortest_path <- function(graph, start, end, path = c()) {
# если нет узлов, связанных с текущим узлом (= тупик), вернется значение NULL
if (is.null(graph[[start]])) return(NULL)
# Добавляем следующий узел к пути
path <- c(path, start)
# Если достигли конца
if (start == end) return(path)
# Инициализация пустого пути
shortest <- NULL
# Цикл по всем узлам, связанным с текущим узлом
for (node in graph[[start]]) {
# Продолжаем, только если связанный узел еще не находится в пути
if (!(node %in% path)) {
# Вызываем рекурсию с текущего узла
newpath <- find_shortest_path(graph, node, end, path)
# Если новый путь короче, чем кратчайший, то новый путь кратчайший
if (path_length(newpath) < path_length(shortest))
shortest <- newpath
}
}
# Возвращаем кратчайший путь
shortest
}
# Номер дома, который мы ищем
home <- 1
sum_shortest_path <- Inf
sum_path <- list()
# Ходим по каждой вершине
for (i in 1:8){
sum <- 0
for (j in 1:8){
# Если это не один и тот же дом
if(i != j){
sum <- sum + as.integer(path_length(find_shortest_path(graph, as.character(i), as.character(j))))
}
}
sum_path <- append(sum_path, sum)
if(sum_shortest_path > as.integer(sum)){
home <- i
sum_shortest_path <- sum
}
}
home
sum_path
home
